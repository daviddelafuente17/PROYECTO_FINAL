{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PAIu-99dYpNY",
    "outputId": "1dbacc28-f7e6-4dae-d26b-8eaef876ac63"
   },
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "import shutil\n",
    "import os\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "print(\"Descargando dataset compatible con tus clases (Benign/Pre/Pro)...\")\n",
    "\n",
    "path = kagglehub.dataset_download(\"mehradaria/leukemia\")\n",
    "print(f\"Dataset en cach\u00e9: {path}\")\n",
    "\n",
    "possible_roots = [\n",
    "    Path(path) / \"Original\",\n",
    "    Path(path),\n",
    "]\n",
    "\n",
    "source_root = None\n",
    "for p in possible_roots:\n",
    "    if p.exists() and any(p.glob(\"*Benign*\")):\n",
    "        source_root = p\n",
    "        break\n",
    "\n",
    "if source_root is None:\n",
    "    source_root = Path(path)\n",
    "    print(f\"AVISO: No encontr\u00e9 la subcarpeta 'Original'. Buscando en la ra\u00edz: {source_root}\")\n",
    "else:\n",
    "    print(f\"Carpeta fuente localizada en: {source_root}\")\n",
    "\n",
    "target_classes = [\"Benign\", \"Pre\", \"Pro\"]\n",
    "base_dir = Path(\".\")\n",
    "\n",
    "print(\"Limpiando carpetas de entrenamiento antiguas...\")\n",
    "for dir_name in [\"train\", \"validation\", \"test\"]:\n",
    "    if (base_dir / dir_name).exists():\n",
    "        shutil.rmtree(base_dir / dir_name)\n",
    "\n",
    "print(f\"Extrayendo solo las clases: {target_classes}...\")\n",
    "\n",
    "for class_name in target_classes:\n",
    "    candidates = list(source_root.glob(f\"*{class_name}*\"))\n",
    "\n",
    "    if not candidates:\n",
    "        print(f\"ALERTA CR\u00cdTICA: No encuentro la carpeta para '{class_name}' en {source_root}\")\n",
    "        try:\n",
    "            print(f\"   Contenido disponible: {[d.name for d in source_root.iterdir() if d.is_dir()]}\")\n",
    "        except:\n",
    "            print(\"   No se pudo listar el directorio.\")\n",
    "        continue\n",
    "\n",
    "    class_source = candidates[0]\n",
    "\n",
    "    images = [f for f in class_source.iterdir() if f.suffix.lower() in ['.jpg', '.jpeg', '.png', '.bmp']]\n",
    "\n",
    "    if len(images) == 0:\n",
    "        print(f\"La carpeta {class_source.name} est\u00e1 vac\u00eda.\")\n",
    "        continue\n",
    "\n",
    "    print(f\"Clase '{class_name}': encontradas {len(images)} im\u00e1genes en '{class_source.name}'\")\n",
    "\n",
    "    train_imgs, temp_imgs = train_test_split(images, test_size=0.3, random_state=42)\n",
    "    val_imgs, test_imgs = train_test_split(temp_imgs, test_size=0.5, random_state=42)\n",
    "\n",
    "    def copy_files(file_list, split_name):\n",
    "        dest_dir = base_dir / split_name / class_name\n",
    "        dest_dir.mkdir(parents=True, exist_ok=True)\n",
    "        for file in file_list:\n",
    "            shutil.copy(file, dest_dir / file.name)\n",
    "\n",
    "    copy_files(train_imgs, \"train\")\n",
    "    copy_files(val_imgs, \"validation\")\n",
    "    copy_files(test_imgs, \"test\")\n",
    "\n",
    "print(\"\\nOrganizaci\u00f3n completada!\")\n",
    "\n",
    "try:\n",
    "    print(\"\\nEstado final de las carpetas:\")\n",
    "    for split in [\"train\", \"validation\", \"test\"]:\n",
    "        if (base_dir / split).exists():\n",
    "            print(f\"   {split}: {os.listdir(base_dir / split)}\")\n",
    "        else:\n",
    "            print(f\"   {split}: no se cre\u00f3 (Fall\u00f3 la descarga)\")\n",
    "except:\n",
    "    pass\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "pip install transformers datasets torch torchvision evaluate scikit-learn accelerate"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7Wf1q8fMZh3F",
    "outputId": "f5fa4ee3-8047-450c-9bc7-9ca1337ba7d0"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoImageProcessor, ResNetForImageClassification, TrainingArguments, Trainer\n",
    "import evaluate\n",
    "import numpy as np\n",
    "from torchvision.transforms import Compose, Normalize, RandomResizedCrop, Resize, ToTensor, CenterCrop\n",
    "from transformers import EarlyStoppingCallback\n",
    "\n",
    "dataset_root = \".\"\n",
    "\n",
    "labels = [\"Benign\", \"Pre\", \"Pro\"]\n",
    "label2id = {label: i for i, label in enumerate(labels)}\n",
    "id2label = {i: label for i, label in enumerate(labels)}\n",
    "\n",
    "dataset = load_dataset(\"imagefolder\", data_dir=dataset_root)\n",
    "if \"validation\" not in dataset and \"val\" in dataset:\n",
    "    dataset[\"validation\"] = dataset[\"val\"]\n",
    "\n",
    "checkpoint = \"microsoft/resnet-50\"\n",
    "processor = AutoImageProcessor.from_pretrained(checkpoint)\n",
    "\n",
    "normalize = Normalize(mean=processor.image_mean, std=processor.image_std)\n",
    "\n",
    "train_transforms_func = Compose([\n",
    "    RandomResizedCrop(processor.size[\"shortest_edge\"]),\n",
    "    ToTensor(),\n",
    "    normalize,\n",
    "])\n",
    "\n",
    "val_transforms_func = Compose([\n",
    "    Resize(processor.size[\"shortest_edge\"]),\n",
    "    CenterCrop(processor.size[\"shortest_edge\"]),\n",
    "    ToTensor(),\n",
    "    normalize,\n",
    "])\n",
    "\n",
    "def preprocess_train(example_batch):\n",
    "    example_batch[\"pixel_values\"] = [\n",
    "        train_transforms_func(image.convert(\"RGB\")) for image in example_batch[\"image\"]\n",
    "    ]\n",
    "    del example_batch[\"image\"]\n",
    "    return example_batch\n",
    "\n",
    "def preprocess_val(example_batch):\n",
    "    example_batch[\"pixel_values\"] = [\n",
    "        val_transforms_func(image.convert(\"RGB\")) for image in example_batch[\"image\"]\n",
    "    ]\n",
    "    del example_batch[\"image\"]\n",
    "    return example_batch\n",
    "\n",
    "dataset[\"train\"].set_transform(preprocess_train)\n",
    "dataset[\"validation\"].set_transform(preprocess_val)\n",
    "if \"test\" in dataset:\n",
    "    dataset[\"test\"].set_transform(preprocess_val)\n",
    "\n",
    "model = ResNetForImageClassification.from_pretrained(\n",
    "    checkpoint,\n",
    "    num_labels=len(labels),\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    "    ignore_mismatched_sizes=True\n",
    ")\n",
    "\n",
    "accuracy = evaluate.load(\"accuracy\")\n",
    "f1_metric = evaluate.load(\"f1\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    acc = accuracy.compute(predictions=predictions, references=labels)\n",
    "    f1 = f1_metric.compute(predictions=predictions, references=labels, average=\"weighted\")\n",
    "    print(\"F1:\", f1[\"f1\"])\n",
    "    return {\"accuracy\": acc[\"accuracy\"], \"f1\": f1[\"f1\"]}\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./resnet-50-finetuned-leucocitos\",\n",
    "    remove_unused_columns=False,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=5e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=15,\n",
    "    warmup_ratio=0.1,\n",
    "    logging_steps=10,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    save_total_limit=2,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset[\"train\"],\n",
    "    eval_dataset=dataset[\"validation\"],\n",
    "    tokenizer=processor,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)]\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "save_path = \"./modelo_final_entrenado\"\n",
    "trainer.save_model(save_path)\n",
    "processor.save_pretrained(save_path)\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "b752227269044c009a13ccfe62b0a70b",
      "254d4a59b0c7427bbee34972b4547298",
      "75795fc6e55f4d9fb470364939294c7e",
      "7a21f584539f47a9a1d3f79dc2839e80",
      "bd4517ed223a430c8261675eb683ff24",
      "d6f8fa2f5f7546fbbef1842da920b184",
      "9496c6ef194947daae2dd6651b6b1c12",
      "db96cda3ef06440eaea9c90c67cc29ed",
      "e6fc1500ab244e4a9587da26766e4411",
      "a551d27431ff4d4aab50cab03b79f6d0",
      "79a1b4d6824943ada55e60271f3c71c4",
      "6c45e251411c4cc5ad646dc202a0ff6d",
      "af7ca888b8144892847ad2b5f6a872c5",
      "0ea97460fa6d435a92c77f69946bb8a2",
      "c90454d6ad2f4e819d219e1306c21f39",
      "649254b9745844beaea3b4e77da10e1f",
      "5d70e7d477da4a808e9de5b27667d117",
      "98cb232d33924403a8d24daa8473000e",
      "7f62bb69a8c048d8b6f18b050b2b07a7",
      "af1428741547480c94dd8131d2fc67eb",
      "7146ed5f5df84a70b5743a41e06b557a",
      "680e8cabfe86491da53c751860b0d5c0",
      "a7da319487e942ec9fb13b12c8d3f1fe",
      "8f7477f5220647b883fb223abbb74dd4",
      "145075ce4f3146549734cefb38abfc21",
      "7ab8ecac885c4688ad8770f4da1e4ac0",
      "d517f5b6d4e74bea80b3a32b51f7c699",
      "c2b4465955ab48829d495b9055452c22",
      "0b995bbcaff34c8aace61f1590e2f9de",
      "93bcc97a32ed47af95aafdc0ec84e8e1",
      "9bf59c5ff71247349fce8c815d869f41",
      "2b7de0d134c74442818a5a5f3c715b25",
      "8fb228412fc740888fdee84183ea8611",
      "eeb39d7d07ff4facbe89d308438b726b",
      "b5aa5ba292da461d87d7d55eecebc70d",
      "41073551d7884aa999a40b828a56cc4b",
      "bbc929acc71b425fb92ffe6ef389fe56",
      "8d623752b57343c989c023acf7d49673",
      "388a2c3e1e8847f3af680bac3113106b",
      "dca97262ad0942a7ad4dd7ee589ef50a",
      "0c5ce43b69dc48da82042c722cdb24b8",
      "92e49f095ab041e79b2bdbd12bca985d",
      "bb844e5828ba4799aa7e019f365377a0",
      "28f708dcc09346389ebb6a69e48507ab",
      "b4ec58e95eb444799640ade08a56df3a",
      "654687bccb1f4f66830696cc73b56f4e",
      "8e4de3bb7c2747568b7d90fd8d6c8cd5",
      "88a6ef812fb64189a075ce7a38987456",
      "3c3a4be40e194cbbb3fe461ce49371ba",
      "5b6af3471f5d4b76a103d5e329cfcd8b",
      "39d1927fbde346178c5bdf29b189fc5d",
      "b240698be6ce4128899746e3cf7b1f47",
      "34b5fbe6229746ff85da493287ddbceb",
      "676923067d684b14ab95f7f71f38dce1",
      "d73117c1a2ca4db0991a96af548d7bfb",
      "ad0e80355a1e47adab14c76217d95b3d",
      "f89aaf392832457c872cd6c34834896d",
      "c416ad54701a46be8c56a1172b4ffe46",
      "f55e5f2cee9c4832a31cde55ae77dc3e",
      "b19186b0c09b4a66b6f52c9051b087c2",
      "f1e2bec38c314929a964f7dffbd49b7d",
      "fa8b2c4a3b4b4c1cbab4ed071910fd95",
      "a6a9abdfd8f240d59fa92455e3c6ad74",
      "30f82b15f28546818cd9b5738582f097",
      "1d679a9409974a8c870510643f81df1b",
      "76c2e00ad4af4b17ba47c41dc8972057",
      "8b3c979a288a453dbbd711d676bdbb9d",
      "21d69860acf74c21ad40cfaa0a0c9706",
      "89fef6bf9dc64403b486760ad9f32c3a",
      "d934caf3c96744eebcd9cfb2ea0870b0",
      "f709377e6a0f46ee8494de77b79bbca9",
      "6dfcbf149f504760a97676785cef2b88",
      "681fb952e89c4a5b9e52753ceb1f7504",
      "9f5febf94f964529ad9f4c02134365a6",
      "54660e2682424dc1b1bc1bbda9c0b064",
      "989bf04581f24268bcf6e6281a54e649",
      "38828d227d504e73bb75c2f4f25b3549",
      "91e6bcdcbad84c879ae7ce3af885d134",
      "895eea054ed84088b3dedcdacd8e2e40",
      "4fa9581c341347adaccabeb7a067efc1",
      "ece00aeb592b4cb18bf0c3261a70721d",
      "bf31769747de47bca6dd429ea79b39c8",
      "d358e23c741b45889e8360b02568f097",
      "252f91ee9fdc4751ae6dc8589f4235eb",
      "91aafa27fc624c32b272d2f3e7188966",
      "34158dff7d624e19a914191c96a18355",
      "185676e59b13475a8e76a88e9eeb738f",
      "bf12103b92414295a22311d5215b063a",
      "6b979e1622b14f9da73a587bcad5e9e4",
      "d47c26e11a604bc4815084b01812dff8",
      "2ed9b89722d146ebb4d4bb6b854b63b0",
      "913966325b3c4c6b99113dd0b3a16dee",
      "96b09d8c38b0486fb9e96806bb2fbdf3",
      "a9417548ae254da98b37a2350f58b3da",
      "67b4a2c9389c43718ca8026b43f8d357",
      "062b0d2319904d8bb69bab0d13f1e3a0",
      "72321a24808941a4accdd96f0d98160b",
      "70b2be3fca5a43b4b2d05f7750349d9c",
      "add647136d6b4ff897b51335bc977ccb",
      "8b263e9b65cf45e6a10f687ed9f803c1",
      "648556dca1184e1f9797652a55f39e87",
      "db284308504e4e088184ae7efb8e66cc",
      "70c79419d96f41699e13f2ba50096f66",
      "e2138ea7e3dc48fa92a5bcabf70e53a6",
      "1b160e5efba34b22bd26f670054e379c",
      "0209ad4c98184aa798669bc2aa5c70d2",
      "5f0f08dcab974dfdb34fb9e09a4418c8",
      "5e44b7f257f34a079c0e1f5829943c2c",
      "e8c7dcd0dcb44fb08283f372c1808105",
      "a527bd9404584cb9b8fb923da7601763",
      "b78e020a044f449dbadc159f82abe85d",
      "f870096f103a4455b11412cd061e4e8e",
      "76c922519ff14322b68e140baecdc8c8",
      "9dab77a6594945f386db437e18492f1c",
      "805119c044aa4e87a1dd39e18f218bcb",
      "dfb5a52a415b46cf8ff3ebce4aad79a2",
      "8e410655d02b4bd9a074d9f21dc83ddf",
      "e3756ddaf9684220800087b637b4392a",
      "4ef36dd299fa47778b3b622c48ee6269",
      "274a5e79e41a44b397a7f8bdce7c336e",
      "47f3d9f4b8fe4d089a1fdd88c9a01abb",
      "6657f226507041728b9e745b88c92c03",
      "cc878a009cf44c2aabd457c89ae60a3c",
      "6b6e3ba1af2b403f83eff79b1b913f57",
      "1938b51190c04bf5bc3021b33d0c18fc",
      "9c6e723ebd9c470daad520eca1aa2824",
      "824211a0a0de4bd189bb9edccc5a720c",
      "9039ea11e6674d7b9f63d3b4ab7d8dd4",
      "9a3cf1720dbf4fa1aad6086d27381aa1",
      "76e0edc34c244e899bdbd22e122fc74a",
      "4fabe9f4f3a34ba9a21d08c598379678",
      "2b6e9b677d6148a99833fc16646aaeee",
      "bd101058907948e1800363d77afb33e2",
      "de70d540bd4c4ee5ac8cf647bc4d77e9",
      "44d39fa5e9c2448e851f1bfc87bd08a5",
      "753f33058102427a8c4138ad00d0664d",
      "92a9a133fd604c109945ed92f5723c21",
      "9fdfebe78ba14ea7a4bde21d109c9910",
      "d0b8d7bd4e244aa3bfbe04a24059c571",
      "551631fa573c4908b790be7741dcfb61",
      "8bf23315e6d1485a9df08fed448f38c7",
      "22c4cc4400bd4114862bdc7eb6abeac6",
      "1dc1b0b2023a483db01c3d5720d53013",
      "0c621e596e1a40f096b49e83793e115e",
      "9e8d39c0bde24e75925c95ca1a07f904",
      "dcc07cf39af64182b1499a6d621d7dbe",
      "bd3c797342f647088a1733642b500059",
      "c59eb1d46a474ea5ae64226d2e926ac8",
      "be0bb993c7cb4d118b2fc0c78f63434b",
      "dd4d8871020849ce9d8d71938c792108",
      "96d276b79f1b4e21ab7480ec3fbfba10",
      "9b08973363a048e68b0d60df73a0f6bb",
      "dd8ef73f4d104096a09bb1e1a551a45e",
      "a1ca521b70ec409585f360abd0fbdb5c"
     ]
    },
    "id": "mwxOK6-oZnWf",
    "outputId": "ac1ad863-0463-41f3-d2fd-ce35e8b7b088"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install matplotlib scikit-learn"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sUZohcagcaIM",
    "outputId": "009c83b1-3e54-4d30-e743-47f11a57aaed"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from transformers import AutoImageProcessor, ResNetForImageClassification\n",
    "from datasets import load_dataset\n",
    "import numpy as np\n",
    "\n",
    "print(\"Recargando dataset para tener las im\u00e1genes originales...\")\n",
    "dataset = load_dataset(\"imagefolder\", data_dir=\".\")\n",
    "\n",
    "path_modelo = \"./modelo_final_entrenado\"\n",
    "model = ResNetForImageClassification.from_pretrained(path_modelo)\n",
    "processor = AutoImageProcessor.from_pretrained(path_modelo)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model.to(device)\n",
    "\n",
    "print(\"Evaluando el set de VALIDATION... (Procesando...)\")\n",
    "\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "for item in dataset[\"validation\"]:\n",
    "    y_true.append(item[\"label\"])\n",
    "    inputs = processor(item[\"image\"].convert(\"RGB\"), return_tensors=\"pt\")\n",
    "    inputs = inputs.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = model(**inputs).logits\n",
    "\n",
    "    predicted_label = logits.argmax(-1).item()\n",
    "    y_pred.append(predicted_label)\n",
    "\n",
    "labels_names = dataset[\"validation\"].features[\"label\"].names\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels_names)\n",
    "disp.plot(cmap=\"Blues\", ax=ax, values_format=\"d\", colorbar=False)\n",
    "\n",
    "plt.title(\"Matriz de Confusi\u00f3n: Set de Validaci\u00f3n\")\n",
    "plt.show()\n",
    "\n",
    "acc = np.sum(np.diag(cm)) / np.sum(cm)\n",
    "print(f\"\\nPrecisi\u00f3n (Accuracy) en VALIDATION: {acc:.2%}\")\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 883,
     "referenced_widgets": [
      "e9d8096a06f445c4b3072acf399fbbfe",
      "b69ae5082ea743e79acc6bf7ec6de6ce",
      "3fbae4cc7f7b486d9d80e17ceb780221",
      "f22de3b1b75e47e1a86a6f67bc84492c",
      "163e51fffcf04911a6686b2b3863eb67",
      "42b985a95e54434c9166b140b241c09c",
      "3e7ca00b67f14680a625b53f05302b87",
      "62a03dd7868740d49e56e1ac8bcc675b",
      "940ed33250194cff893093c1bad7f0b2",
      "a76e9a61682a4594b4e94abe546812aa",
      "65d57cfae2c245d8be0d72e052b83921",
      "301ea148e53446a48f3fbfb73e8776a1",
      "fccf25da2f6a4e45b2b8362563a355fa",
      "7fef4807c246428e8886408c09bd6dd4",
      "0c35fb1496da45e88c5e22b7fa3a6b8a",
      "97f7c6132f854a3c8beeedea5e4f6b99",
      "397f2e164d7943aeafff17f68d2ab683",
      "1071a09c175a4727bec91a369222d0bd",
      "5472148f07c04e40bda850d69df2c8b6",
      "206291667f094877a6a2f15c54600d3a",
      "98621f40a75445baa0e9553eef0c8510",
      "dcfaad22b4a04d42be96fa78664781a1",
      "fbe20040a62d4dd7a42bf4ad17f94af7",
      "601ce87129114b0393ebdf5256317732",
      "080c54d7265a4df488f271a28150265d",
      "37f6c4e8c509482aaed080a42fb24ff5",
      "4f91edb6eb90484b849d2ecec0e76695",
      "661861a3421e46e2902f410b6d3c5d03",
      "fa77efb5981a4c32a7c1e4e78fc5afd6",
      "61b3464e1fa14f29b7ca565959f998d4",
      "b0aca98f6ac4486096484336b517f5ee",
      "70e05082d5144cecb02f4fc743cd66e4",
      "cbe5474501694b73bbca92ccff81bc06"
     ]
    },
    "id": "hPKfekbkcKrj",
    "outputId": "81326cfc-155a-4031-9599-f17701a560f5"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from transformers import AutoImageProcessor, ResNetForImageClassification\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "path_modelo = \"./modelo_final_entrenado\"\n",
    "processor = AutoImageProcessor.from_pretrained(path_modelo)\n",
    "model = ResNetForImageClassification.from_pretrained(path_modelo)\n",
    "\n",
    "image_path = \"/content/validation/Pro/WBC-Malignant-Pro-023.jpg\"\n",
    "\n",
    "try:\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    inputs = processor(image, return_tensors=\"pt\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = model(**inputs).logits\n",
    "\n",
    "    pred_idx = logits.argmax(-1).item()\n",
    "    pred_label = model.config.id2label[pred_idx]\n",
    "\n",
    "    probs = F.softmax(logits, dim=-1)\n",
    "    conf = probs[0][pred_idx].item() * 100\n",
    "\n",
    "    print(f\"Resultado: {pred_label} ({conf:.2f}%)\")\n",
    "    display(image.resize((150,150)))\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 184
    },
    "id": "PXgAeXP1ciuR",
    "outputId": "75754664-37b8-470b-aec3-630d9f5a3d79"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I0ONwRaEkXsG",
    "outputId": "83b079d6-a2eb-479e-854b-cfe4eb506370"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "!find \"/content/drive\" -maxdepth 4 -name \"*.ipynb\"\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Uz6G9XkxknBZ",
    "outputId": "6f1acd2f-cbe9-465c-d5fc-36f739648d9e"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import json\n",
    "\n",
    "input_path = \"/content/drive/MyDrive/Colab Notebooks/Copia de Untitled2.ipynb\"\n",
    "output_path = \"/content/notebook_limpio.ipynb\"\n",
    "\n",
    "with open(input_path, \"r\") as f:\n",
    "    nb = json.load(f)\n",
    "\n",
    "if \"metadata\" in nb:\n",
    "    for k in [\"widgets\", \"widget\", \"colab\"]:\n",
    "        if k in nb[\"metadata\"]:\n",
    "            del nb[\"metadata\"][k]\n",
    "\n",
    "for cell in nb.get(\"cells\", []):\n",
    "    if \"metadata\" in cell:\n",
    "        for k in [\"widgets\", \"widget\"]:\n",
    "            if k in cell[\"metadata\"]:\n",
    "                del cell[\"metadata\"][k]\n",
    "    if \"outputs\" in cell:\n",
    "        cell[\"outputs\"] = []\n",
    "    if \"execution_count\" in cell:\n",
    "        cell[\"execution_count\"] = None\n",
    "\n",
    "with open(output_path, \"w\") as f:\n",
    "    json.dump(nb, f)\n",
    "\n",
    "print(\"Notebook limpio guardado en:\", output_path)\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7pjuf94SlJ-n",
    "outputId": "d9fcf1d0-84c4-4cf7-b81b-09f3fd43e1e6"
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}
